%LINKZÄ http://conferences.sigcomm.org/co-next/2007/papers/studentabstracts/paper46.pdf se 2. THE PROOF-OF-WORK APPROACH
%
%https://www.ideals.illinois.edu/bitstream/handle/2142/17372/TechReport.pdf?sequence=3
%
% Puzzle-based defense mechanisms such as [41, 9, 20, 35, 26] try to correct the imbalance between the cost to the attacker for generating a request and cost to the server for processing a request by demanding a payment, in the form of a puzzle solution, from each client. In a typical puzzle-based scheme, a request must be accompanied by a proof of payment from the client. The payment may be in the form of computation or memory accesses that the client needs to perform to solve the puzzle. Since the amount of resources available to the attacker is limited (even if it is much more than that of the legitimate clients), the attacker will not be able to trivially amplify his attack. There are different kinds of schemes that build on this general principle. Laurie et al. [31] have analyzed proof-of-work schemes in the context of a spam deterrent mechanism and conclude that proof-of-work schemes do not work, because the cost involved for legitimate senders would be too high. However, their economic estimation contains a miscalculation. More importantly, their analysis considers fixed-cost puzzle schemes and does not analyze adaptive proof-of-work schemes proposed by recent DoS counter-measures.

Denial of Service attacks are often possible due to the low price of a request, for an adversary often a single network packet\cite{gunter}, compared to the work the service provider performs. Puzzle-based proof-of-work limits an attacker's possibilities to impose a high work load on a server from a sole client by increasing the cost of each request. \Citeauthor{LaurieC04} argued that Proof of Work, assuming a fixed cost proof-of-work pricing function, would not work. In this section we present an alternate interpretation of proof-of-work incorporating problem scaling and individual adaptation, that may in fact be a practically viable scheme to considerably attenuate the effects of a denial-of-service attack.

The RB-PoW scheme utilises a hash-reversal puzzle very similar to hashcash. The difference to hashcash is that RB-PoW uses SHA2 in place of SHA1, since it is a cryptographically stronger hash\cite{nistsha1}.
The problem definition is a seed $P_i[j]$\footnote{For a precise definition of $P_i[j]$, $i$ and $j$, please see section \ref{text:protonot}.}. The client needs to find $S_i[j]$ such that the computed hash $ h = H(S_i[j]||P_i[j])$ holds the property that the leading $d$ (issued difficulty) digits in the hex representation of $h$ are all equal to zero. 
It is computationally infeasible to find $x$  for a given $h$ such that $ h = \mbox{sha2}(x)$\cite{sha2}, consequently the only way to find $S_i[i]$ is by sequential trial. For $d_{l+1} = d_l + 1 $, only $\frac{1}{16}$ of solutions accepted for difficulty $d_l$ are accepted.
The complexity of finding $S_i[j]$ is thus $O(16^d)$. This is however an amortized complexity, since one can be lucky and find a solution in the first hash test, or be forced to seek nearly the complete solution space.
The actual running time is in fact geometrically distributed with an expected outcome of $16^d$ trials before finding the solution, but the running time may be improved to approach a normal distribution with the introduction of sub-puzzles\cite{subpuzzles}. 
The reputation based proof-of-work model uses subpuzzles to normalise expected solving times but also to scale problem difficulties. To harvest the almost normalised run times we use a minimum of 16 sub-puzzles, as suggested by \citeauthor{subpuzzles}. A (sub-)puzzle set may have a cardinality as large as 256 to enable integer scaling of problem difficulty. The central difficulty scaling model of RB-PoW will be further addressed in section \ref{text:diffscaler}.

\subsection{RB-PoW Protocol}

\subsubsection{Protocol notation}\label{text:protonot}
To formalize the Proof of Work protocol a few notations will be introduced. Consider the following notations:
\\
\\
\indent \begin{minipage}{0.9\linewidth}
\thickmuskip=0mu
${\textbf M_i} \ = $ to be $i^{th}$ execution of the protocol $M$ by either a legitimate user or an adversary. 

${\textbf h} \ = $ a puzzle generator function.

${\textbf t} \ = $ timestamp at time of puzzle generation

${\textbf P[j]} \ = $ the $j^{th}$ sub-puzzle in $P$.

${\textbf m} \ = $ the number of sub-puzzles, this equals to the size of the set $P$. 

${\textbf d} \ = $ an integer indicating the difficulty of the problem set $P$. 

${\textbf S[j]} \ = $ the $j^{th}$ solution in $S$ and a solution to $j^{th}$ sub-puzzle in $P$. 

${\textbf z} \ = $ a function that return the number of most significant bytes that is zero. 
%\vspace*{-10pt}
\end{minipage}

\subsubsection{Protocol description}\label{text:protodesc}
Now let us describe the details of our proposed reputation based puzzle protocol between client and server. Prior to initiating protocol \textbf{M} the client $C_i$ starts by requesting for a service $R_i$ to the server. The server responds with a packaged set of sub-puzzles $P_i$ of size $m$ and a difficulty $d$. Each sub-puzzle $P[1] \dots P[m]$ is a seed derived by $g(t,x)$ where $x$ is value generated uniformly-at-random.

The client $C_i$ must solve each sub-puzzle $P_i[j]$ of $P_i$ by finding a value $S_i[j]$ so that the computed hash $H(S_i[j] \ || \ P_i[j] )$ has at least $d$ leading zeroes. If such a hash is found then the solution $S[j]$ is a solution to the sub-puzzle $P[j]$.

The server then verifies each solution of $S_i$ by computing $H(S_i[j] \ || \ P_i[j])$ with a stored copy of $P_i[j]$ and confirms that the solution has $d$ leading zeroes. If all solutions are correctly computed the client $C_i$'s request $R_i$ will be granted. 

\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}

		\scriptsize
		\matrix (m)[matrix of nodes, column  sep=-15mm,row  sep=1.5mm, nodes={draw=none, anchor=center,text depth=0pt} ]{
		\textbf{\normalsize server} & & \textbf{\hspace*{20pt}\normalsize client}\\[0mm]
		& & \\
		& Initialisation of protocol \textbf{M}& \\
		& service request $R_i$& \\
		generate sub-puzzles \\
		$P[j] := g(t,x), 1\leq j \leq m$\\
		$P_i :=$ $\{\cup_{j=1}^{m}P[j],d\}$ \hfill \\
		& send puzzles & \\
		& & solve each $P[j] \in P$ \\
		& & $S_i := \{S[1 \dots m]\}$ \\
		& send solutions & \\
		verify each $S[j] \in S$ && \\ 
		& grant request $R_i$ & \\
		};
		\draw[shorten <=-1cm,shorten >=-1cm,-latex] (m-4-2.south east)--(m-4-2.south west);
		\draw[shorten <=-1cm,shorten >=-1cm,-latex] (m-8-2.south west)--(m-8-2.south east);
		\draw[shorten <=-1cm,shorten >=-1cm,-latex] (m-11-2.south east)--(m-11-2.south west);
		\draw[shorten <=-1cm,shorten >=-1cm,-latex] (m-13-2.south west)--(m-13-2.south east);
		\end{tikzpicture}
		 \vspace{10pt}
		\caption{Diagram of Proof of Work protocol}\label{tab:protocol}
	 \end{center}
\end{figure}
If the reputation system deems the server to not being under attack i.e. under normal server operation the problem package will be the empty set, indicating that no puzzles are being distributed.
Hence, the client will ''solve'' this empty set with no effort and then respond back to the server.\footnote{This design decision may be questioned, arguing that the handshaking process with empty sets could bring unnecessary load on the server.
However, empty sets will only be distributed when server load is low thus the extra verification can be afforded.}
The server will then verify the solution for $P_i$ and grant access to $R_i$ of protocol \textbf{M}.

If the reputation system deems the server to be under attack the difficulty of the problem set of request $R_i$ will be decided by the historical and current behaviour of client $C_i$. 

The following sections will present server-side metrics needed to define client behaviour and explain assumptions made for the test environment. 
We will precisely define the meaning of client behaviour in our model and finally carry on to develop and describe the reputation based proof-of-work model.

\input{atk_model}


\subsection{Behaviour model}\label{tab:behaviourmodel}
An essential principle of RB-PoW is the RB-PoW definition of fairness:
\begin{figure}[H]
\begin{GrayBox}[0.65\textwidth]
Every client has equal right to the server's resources.
\end{GrayBox}
\caption{RB-PoW Reputation Model Statement}
\end{figure}
The behaviour model does not reason about users as legitimate or malicious in a boolean meaning, it regards each user as a potential evil-doer with varying maliciousness. A ``good'' user is thus a user that is less taxing on the system whereas an adversary is a user that is more taxing on the system than the global average.  

Assumption 4 implies that the demands of a client can be measured by the number of connections concerned makes in a given time-frame, or the inverse: how long time is passed between each request. 
To quantify the behaviour of a user we measure average time between request instead of average request rate per time unit. Behaviour $b_i$ is calculated as an exponential moving average and is recalculated at every request the client performs:
 $$ b_{i} = \alpha\cdot\delta + (1-\alpha)b_{i-1} $$
where $\delta$ is the time difference since the last request. At every request, the global average behaviour $B_i$ is also recalculated:
$$ B_{i} = \beta\cdot\Delta + (1-\beta)B_{i-1} $$
where $\Delta = \delta \cdot n$, $n$ is number of users currently connected to the system. The multiplication averages the time between request and enables us to compare the value to local values. 
One advantage of measuring the time between request versus counting requests during a sampling period is that it can be implemented more efficient and is thus less taxing on the server. However, a more interesting property is the effect on behaviour change rate. Sampling number of request during a period and averaging over $n$ last periods means that a client is considered ``good'' again after being ``bad'' just as fast (in time) as vice versa if a client changes behaviour pattern.
Averaging over the last $n$ requests instead will cause the system to respond faster (in time) if a client start acting maliciously (suddenly increasing request rate) and demanding a longer time for the client to redeem her behaviour.


% In the context of our reputation system, behaviour is defined as the measured time between requests sent to the server. Furthermore, both historical data and close to real-time data are taken into account by the use of a rolling average. However, there is two fundamental differences in the way that global behaviour is computed in comparison to the individual behaviour of a client. The first and most important difference is that the individual client behaviour is rated based on it's own frequency of requests, while the global behaviour is based on the frequency between the requests of all clients. 

% A perhaps a more subtle difference is how much weight the historical behaviour should have. The weight of historical behaviour impacts the rate of change. Thus a higher weight gives a more stable and slower moving measurement of the behaviour. Hence, more fitting for the defining the general behaviour of clients on the server. While a lower weight tend to be closer to real-time measurement thus befitting the individual behaviour of a client.


\subsection{Reputation Mechanism as a Difficulty Scaler}\label{text:diffscaler}
Assumption 5 implies that the DoS protection functionality is unlikely to be activated during normal operation. It also implies that if the server is under attack, the average adversary is likely more taxing on the system than the average legitimate user, unless the offender has access to orders of magnitude more adversaries than the normal user base. This is an indicator of the soundness of the behaviour model introduced in the previous paragraph. 

The client behaviour can generally be divided into three cases:
\begin{itemize}
\item the client $C_i$ behaves in a comparable manner to the general behaviour of all users and the request $R_i$ is responded with a problem difficulty suitable to server load.
\item the client $C_i$ requests lesser resources compared to the general behaviour and the request $R_i$ is responded with a problem difficulty easier than the general difficulty.
\item the client $C_i$ requests more resources compared to the general behaviour and the request $R_i$ is responded with a problem difficulty harder than the general difficulty.
\end{itemize}
Implementation of RB-PoW model:
\begin{minted}[fontsize=\footnotesize]{go}
func rb_scale_model(p Param) Difficulty {
	if math.Max(p.Cpu.Load, p.Cpu.Avg) < cpu_thres {
		return ZeroDifficulty
	}
	if p.Local.LongMean > 2*max(p.Global.ShortMean, p.Global.LongMean) {
		if p.Local.ShortMean > 3*p.Global.LongMean 
		   && math.Max(p.Cpu.Load, p.Cpu.Avg) < cpu_thres+20 {
		    	return ZeroDifficulty
		   }

		return BaseDifficulty
	}
	diff := BaseDifficulty.multiply(1 + int((math.Max(p.Cpu.Avg, cpu_thres) - cpu_thres)))
	return *diff.multiply(1 + int(5*max(0, (p.Global.LongMean)/(p.Local.ShortMean+1))))
}
\end{minted}


\input{metrics}

% We propose a conceptually simple yet in practice effective reputation system. A client is rated based on historical and current behaviour. The reputation mechanism distributes proof of work problems with a difficulty dependant on the individual client behaviour compared to the global average behaviour as well as server load. 

% The basic idea of the RB-PoW scheme is that the server is dimensioned to handle normal load. If the server load is beneath \emph{cpu\_thres}, the server is in a normal state and no PoW scheme needs to be applied. If server load is above {\em cpu\_thres}, PoW may be activated, suspecting all clients as possible adversaries [SOURCE HÄR]. Another foundation of the RB-PoW model is an assumption that legitimate clients utlises a lower request rate than a malicious user. so if the server is under attack we compare the behaviour ( access time ) of the client against global average. If extremely favourable, client may get a free ticket to the zoo, and if extremely taxing on the server client gets an extremely hard problem.  ;)




